{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source:\n",
    "    \n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html#topic=0&lambda=1&term="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import ldaseqmodel\n",
    "from gensim.models import LdaSeqModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import numpy as np\n",
    "from gensim.matutils import hellinger\n",
    "import pandas as pd\n",
    "BASE = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\data\\\\initial_data\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv(BASE+'links_only_sorted_pp.csv', encoding = 'utf8')\n",
    "#df_in = df_in.iloc[:10]\n",
    "df_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file converts text corpora to blei format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "STOPWORDS = nltk.corpus.stopwords.words(\"english\")\n",
    "VOCAB = {}\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocab(docs):\n",
    "    vocab_cnt = 0\n",
    "    for doc in docs:\n",
    "        words = doc.split()\n",
    "        for w in words:\n",
    "            w = w.lower()\n",
    "            if w not in VOCAB:\n",
    "                VOCAB[w] = vocab_cnt\n",
    "                vocab_cnt += 1\n",
    "createVocab(list(df_in['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpus(docs):\n",
    "    for doc in docs:\n",
    "        words = doc.split()\n",
    "        freq_table = {}\n",
    "        for w in words:\n",
    "            w = w.lower()\n",
    "            if w != '' and w in VOCAB:\n",
    "                w_id = VOCAB[w]\n",
    "                if w_id in freq_table:\n",
    "                    freq_table[w_id] = freq_table[w_id] + 1\n",
    "                else:\n",
    "                    freq_table[w_id] = 1\n",
    "        corpus.append(freq_table)\n",
    "createCorpus(list(df_in['full_text']))\n",
    "corpus = [list(table.items()) for table in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_slices = 2\n",
    "slice_vol = int(len(df_in)/float(no_of_slices))\n",
    "\n",
    "time_slice_vol_list = [slice_vol for i in range(no_of_slices)]\n",
    "\n",
    "time_slice_vol_list.append(len(df_in)-sum(time_slice_vol_list))\n",
    "\n",
    "# idx = 0\n",
    "# time_slices = []\n",
    "# for i in range(no_of_slices):\n",
    "#     slice_ = []\n",
    "#     for j in range(slice_vol):\n",
    "#         slice_.append(df_in.iloc[idx]['full_text'])\n",
    "#         idx += 1\n",
    "#     time_slices.append(slice_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict()\n",
    "for key,val in VOCAB.items():\n",
    "    id2word[int(val)] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = LdaSeqModel(corpus=corpus, \n",
    "                     id2word=id2word,\n",
    "                     time_slice=time_slice_vol_list,\n",
    "                     num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.print_topics(time=0)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.print_topics(time=1)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.doc_topics(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
