{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import html\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\data\\\\initial_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        tokens.append(token.lemma_)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "tweet = u\"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "lemmatise(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "def fixup(x):\n",
    "    \"\"\" Cleans up erroroneus characters\"\"\"\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('rt @','@')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_a_tweet(tweet):\n",
    "    tweet = ' '.join([w for w in tweet.split() if not w in stop_words])\n",
    "    tweet = fixup(tweet)\n",
    "    tweet = re.sub(r'^RT @\\w+:', 'xxrtu', tweet).strip() # retweet unmodified\n",
    "    tweet = re.sub(r'^MRT @\\w+:', 'xxrtm', tweet).strip() # retweet modified\n",
    "    tweet = re.sub(r'@\\w+', 'xxatp', tweet).strip() # @Person occurance\n",
    "    tweet = re.sub(r'http\\S+', 'xxurl', tweet).strip() # url occurence\n",
    "    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet).strip() # fix repeating characters\n",
    "    tweet = lemmatise(tweet)\n",
    "    return tweet.lower()\n",
    "    #return tweet\n",
    "tweet = 'aaaaaa Canâ€™t wait to pop out of no where with this one ðŸ¤« untill then imma stay deep in this ðŸŽ’'\n",
    "preprocess_a_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(BASE+'links_only.jsonl') as FI:\n",
    "    for line in FI:\n",
    "        json_data = json.loads(line)\n",
    "        key_val = {}\n",
    "        key_val['created_at'] = json_data['created_at']\n",
    "        key_val['verified'] = json_data['user']['verified']\n",
    "        key_val['name'] = json_data['user']['name']\n",
    "        key_val['full_text'] = preprocess_a_tweet(json_data['full_text'])\n",
    "        key_val['location'] = json_data['user']['location']\n",
    "        key_val['followers_count'] = json_data['user']['followers_count']\n",
    "        key_val['friends_count'] = json_data['user']['friends_count']\n",
    "        data.append(key_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.DataFrame(data)\n",
    "df_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.to_csv(BASE+'links_only_pp.csv', encoding = 'utf8', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv(BASE+'links_only_pp.csv', encoding = 'utf8')\n",
    "df_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in['created_at'] =pd.to_datetime(df_in.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = df_in.sort_values(by='created_at')\n",
    "df_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = df_in.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(re.sub(\"([^\\x00-\\x7F])+\",\"\",' '.join(list(df_in['full_text'])).replace('xxatp', \"\").\n",
    "                                 replace('xxurl', \"\")))\n",
    "\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
