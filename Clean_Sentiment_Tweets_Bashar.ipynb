{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Dataset Source:\n",
    "\n",
    "https://www.kaggle.com/kazanova/sentiment140#training.1600000.processed.noemoticon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import html\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "%matplotlib inline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\data\\\\sentiment_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        tokens.append(token.lemma_)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "tweet = u\"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "lemmatise(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "def fixup(x):\n",
    "    \"\"\" Cleans up erroroneus characters\"\"\"\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('rt @','@')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_a_tweet(tweet):\n",
    "    tweet = ' '.join([w for w in tweet.split() if not w in stop_words])\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    tweet = fixup(tweet)\n",
    "    tweet = re.sub(r'^RT @\\w+:', '', tweet).strip() # retweet unmodified\n",
    "    tweet = re.sub(r'^MRT @\\w+:', '', tweet).strip() # retweet modified\n",
    "    tweet = re.sub(r'@\\w+', '', tweet).strip() # @Person occurance\n",
    "    tweet = re.sub(r'http\\S+', '', tweet).strip() # url occurence\n",
    "    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet).strip() # fix repeating characters\n",
    "    tweet = lemmatise(tweet)\n",
    "    return tweet.lower()\n",
    "    #return tweet\n",
    "tweet = 'aaaaaa Canâ€™t wait to pop out of no where with this one ðŸ¤« untill then imma stay deep in this ðŸŽ’'\n",
    "preprocess_a_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv(BASE+'training.1600000.processed.noemoticon.csv', \n",
    "                    encoding='ISO-8859-1', header = None)\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset has the following 6 fields:\n",
    "\n",
    "target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "ids: The id of the tweet ( 2087)\n",
    "\n",
    "date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "text: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df_in.index:\n",
    "    df_in.at[idx,'text'] = preprocess_a_tweet(df_in.iloc[idx]['text'])\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_in.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.to_csv(BASE+'sentiment_tweets_pp.csv', encoding = 'utf8', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_in)*.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_in, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(BASE+'train_pp.csv', encoding = 'utf8', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(BASE+'test_pp.csv', encoding = 'utf8', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(re.sub(\"([^\\x00-\\x7F])+\",\"\",' '.join(list(df_in['text']))))\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
