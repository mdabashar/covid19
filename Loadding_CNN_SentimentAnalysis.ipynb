{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring Model\n",
    "1. Load Tokenizer\n",
    "2. Load Model Architecture\n",
    "3. Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_PATH = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\StoredModels\\\\CNN\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(STORE_PATH+'tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(STORE_PATH+'model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(STORE_PATH+\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "maxlen = np.load(STORE_PATH+'maxlen.npy')\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\data\\\\sentiment_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BASE+'test_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(BASE+'test_pp.csv', encoding='utf8')\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['target', 'text']]\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list(df_test['text'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = tokenizer.texts_to_sequences(X_test)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "xtest = pad_sequences(xtest, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = (np.array(df_test['target'])/4).astype(int)\n",
    "ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "p = loaded_model.predict(xtest,verbose=0)\n",
    "p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [np.argmax(x) for x in p]\n",
    "predicted[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "predicted = np.array(predicted)\n",
    "actual = ytest\n",
    "\n",
    "tp = np.count_nonzero(predicted * actual)\n",
    "tn = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "fp = np.count_nonzero(predicted * (actual - 1))\n",
    "fn = np.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "print('True Positive', tp)\n",
    "print('True Negative', tn)\n",
    "print('False Positive', fp)\n",
    "print('False Negative', fn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "fmeasure = (2 * precision * recall) / (precision + recall)\n",
    "cohen_kappa_score = cohen_kappa_score(predicted, actual)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual, predicted)\n",
    "auc_val = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc_val = roc_auc_score(actual, predicted)\n",
    "\n",
    "print('Accuracy', accuracy)\n",
    "print('Precision', precision)\n",
    "print('Recall', recall)\n",
    "print('f-measure', fmeasure)\n",
    "print('cohen_kappa_score', cohen_kappa_score)\n",
    "print('auc', auc_val)\n",
    "print('roc_auc', roc_auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Predict on unlabelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Unlabelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_UNLABELLED = 'C:\\\\Users\\\\basharm\\\\PythonJupyter\\\\CoVID19CodeGit\\\\data\\\\australian_space\\\\'\n",
    "BASE_UNLABELLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "rows = []\n",
    "with open(BASE_UNLABELLED+'au_tweet_out.txt') as FI:\n",
    "    for i, line in enumerate(FI):\n",
    "        if i==0:\n",
    "            columns = line.strip().split('\\t')\n",
    "        else:\n",
    "            row = line.strip().split('\\t')\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un = pd.DataFrame(rows)\n",
    "df_un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un = df_un.drop(3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un.columns = ['Text', 'Time', 'Location', 'Name']\n",
    "df_un.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xun = tokenizer.texts_to_sequences(list(df_un['Text'].astype(str)))\n",
    "xun = pad_sequences(xun, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pun = loaded_model.predict(xun,verbose=0)\n",
    "pun[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_un = [np.argmax(x) for x in pun]\n",
    "predicted_un[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un['Sentiment'] = predicted_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un['Time'] =pd.to_datetime(df_un['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un = df_un.sort_values(by='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un = df_un.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df_un)-sum(df_un.Sentiment))/len(df_un)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_un.to_csv(BASE_UNLABELLED+'au_tweet_sentiment.csv', index=None, encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
